#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass pwszdpl
\options pdflatex
\use_default_options false
\maintain_unincluded_children false
\language polish
\language_package default
\inputencoding latin2
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement !h
\paperfontsize 11
\spacing onehalf
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 0
\use_esint 0
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Indeks
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language polish
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Ukryte Modele Markowa
\end_layout

\begin_layout Section
Wprowadzenie teoretyczne
\end_layout

\begin_layout Standard
\begin_inset Quotes pld
\end_inset

Ukryte Modele Markowa stanowią serce większości współczesnych systemów rozpoznaw
ania mowy.
\begin_inset Quotes prd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Ops"

\end_inset

 Sprawdzają się również w wielu innych zastosowaniach, najczęściej tam gdzie
 mamy doczynienia z sygnałem niederministycznym, m.in.:
\end_layout

\begin_layout Itemize
rozpoznawanie obrazów,
\end_layout

\begin_layout Itemize
modelowanie DNA,
\end_layout

\begin_layout Itemize
modelowanie danych ekonomicznych.
\end_layout

\begin_layout Standard
Pierwsze prace na temat Ukrytych (niejawnych) Modeli Markowa prowadził Baum
 wraz ze współpracownikami w latach 60-tych oraz 70-tych.
 Dotyczyły one metody estymacji parametrów modeli HMM nazwanej algorytmem
 Bauma-Welcha.
 
\begin_inset CommandInset citation
LatexCommand cite
key "RmHMM"

\end_inset

 Do celów rozpoznawania mowy zostały użyte poraz pierwszy w połowie lat
 siedemdziesiątych przez pracowników firmy IBM.
 W obecnych czasach jest to najczęściej wykorzystywane narzędzie klasyfikacji
 w systemach rozpoznawania mowy.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Ops"

\end_inset

 Opisane zostało w wielu pozycjach literaturowych, m.in.
 w 
\begin_inset CommandInset citation
LatexCommand cite
key "Fosr"

\end_inset

, tutaj zostanie przedstawiony jedynie ogólny zarys tej metody.
\end_layout

\begin_layout Standard
W HMM wykorzystywane są modele statystyczne posiadające własności Markowa
 pierwszego rzędu co oznacza, że aktualny stan modelu zależy tylko od stanu
 poprzedniego.
 W ukrytym modelu Markowa zakłada się, że stany są niewidoczne dla obserwatora,
 natomiast wyjście (wartości obserwowane) jest jawne, stąd w nazwie występuje
 słowo 
\emph on
ukryte
\emph default
.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Rozp"

\end_inset

 W przypadku mowy, wartości obserwowane bądź też obserwacje są to wektory
 cech wyekstrahowane z pojedynczej ramki sygnału mowy.
 Ukryty model Markowa opisuje pewien układ (proces stochastyczny), który
 w danym momencie może znajdować się tylko w jednym ze stanów.
 
\end_layout

\begin_layout Standard
Ogólne założenia metody HMM z punktu widzenia rozpoznawania mowy można przedstaw
ić następująco:
\end_layout

\begin_layout Itemize
dla każdej klasy (np.
 głoski, fonemu lub słowa) tworzy się pewien model stochastyczny 
\begin_inset Newline newline
\end_inset


\begin_inset Formula $\text{Λ}_{m},m=1,\text{…},M$
\end_inset

, gdzie M to liczba klas,
\end_layout

\begin_layout Itemize
dla każdej nieznanej sekwencji stanów 
\begin_inset Formula $X$
\end_inset

 oblicza się prawdopodobieństwa generowania sekwencji wektorów 
\begin_inset Formula $p(O,X|\text{Λ}_{m})$
\end_inset

 przez modele dla poszczególnych klas,
\end_layout

\begin_layout Itemize
klasyfikacja odbywa się na zasadzie największego prawdopodobieństwa, 
\begin_inset Formula $X$
\end_inset

 jest przypisywane do takiej klasy 
\begin_inset Formula $\text{Λ}_{m}$
\end_inset

, która posiada największe prawdopodobieństwo 
\begin_inset Formula $p(O,X|\text{Λ}_{m})$
\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand cite
key "TM"

\end_inset


\end_layout

\begin_layout Section
Parametry modeli Markowa
\end_layout

\begin_layout Standard
Macierz przejść definiuje możliwe przejścia pomiędzy stanami oraz wartości
 ich prawdopodobieństw:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
\begin{bmatrix}0 & a_{12} & 0 & 0 & 0\\
0 & a_{22} & a_{23} & 0 & 0\\
0 & 0 & a_{33} & a_{34} & 0\\
0 & 0 & 0 & a_{44} & a_{45}\\
0 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Dla każdego przejścia z chwili czasowej 
\begin_inset Formula $t$
\end_inset

 do 
\begin_inset Formula $t+1$
\end_inset

 przejście ze stanu 
\begin_inset Formula $x{}_{i}$
\end_inset

 do stanu 
\begin_inset Formula $x{}_{j}$
\end_inset

 następuje z prawdopodobieństwem 
\begin_inset Formula $a{}_{ij}$
\end_inset

.
\end_layout

\begin_layout Standard
Suma prawdopodobieństw w wierszach a więc suma wszystkich wyjść ze stanu
 zawsze wynosi jeden.
\end_layout

\begin_layout Standard
Na rysunku 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys8"

\end_inset

 widoczny jest 5-cio stanowy model markowa typu left-to-right z przejściami
 zapisanymi w powyższej macierzy.
\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename hmm.png
	display false

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Model Markowa 5-cio stanowy typu left-to-right
\begin_inset CommandInset label
LatexCommand label
name "rys8"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
W rozpoznawaniu mowy zazwyczaj wykorzystywane są modele typu left-to-right
 (wyjątek to np.
 model ciszy) oznacza to, że z aktualnego stanu możliwe jest przejście do
 stanu kolejnego, pozostanie w tym stanie, lub przejście o kilka stanów
 do przodu, nie można się cofać.
 
\end_layout

\begin_layout Standard
Stan początkowy oraz końcowy czyli w przypadku 5-cio stanowego modelu stan
 1 oraz stan 5 zwane są stanami nieemitującymi, ponieważ nie generują żadnych
 obserwacji, mają za zadanie jedynie rozpocząć oraz zakończyć proces.
\end_layout

\begin_layout Standard
Dla każdej ramki czasowej 
\begin_inset Formula $t$
\end_inset

, może być przez każdy stan 
\begin_inset Formula $s_{θ}$
\end_inset

 modelu 
\begin_inset Formula $\text{Λ}{}_{m}$
\end_inset

 generowany wektor obserwacji 
\begin_inset Formula $o_{t}$
\end_inset

.
 Suma prawdopodobieństw generowania obserwacji dla jednego stanu zawsze
 wynosi jeden.
\end_layout

\begin_layout Standard
Dla modelu na rysunku 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys8"

\end_inset

 do wygenerowania wszystkich wektorów obserwacji, w kolejności od 
\begin_inset Formula $o_{1}$
\end_inset

 do 
\begin_inset Formula $o_{6}$
\end_inset

 potrzebna jest sekwencja stanów 
\begin_inset Formula $X=1,\,2,\,2,\,2,\,3,\,4,\,4,\,5$
\end_inset

.
\end_layout

\begin_layout Standard
Obserwacje (wektory cech) 
\begin_inset Formula $o_{t}$
\end_inset

 emitowane są z prawdopodobieństwem 
\begin_inset Formula $b{}_{j}$
\end_inset

 określanym zazwyczaj jako wielowymiarowy rozkład Gaussa: 
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
b_{j}(o_{t})=\frac{1}{\sqrt{(2π)^{n}\left|\sum_{j}\right|}}e^{-\frac{1}{2}(o_{t}-\text{μ}_{j})'\sum_{j}^{-1}(o_{t}-\text{μ}_{j})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Gdzie:
\end_layout

\begin_layout Standard
\begin_inset Formula $\sum_{j}$
\end_inset

- macierz kowariancji,
\end_layout

\begin_layout Standard
μ
\begin_inset Formula $_{j}$
\end_inset

- wektor średni obserwacji,
\end_layout

\begin_layout Standard
n - wymiar wektora obserwacji.
\end_layout

\begin_layout Standard
Prawdopodobieństwo obserwacji możemy również aproskymować za pomocą mieszaniny
 wielowymiarowych rozkładów Gaussa:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
p_{j}(o_{t})=\sum_{k=0}^{K-1}c_{jk}b_{jk}(o_{t})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
\sum_{k=0}^{K-1}c_{jk}=1
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Gdzie:
\end_layout

\begin_layout Standard
\begin_inset Formula $K$
\end_inset

 - liczba rozkładów Gaussa,
\end_layout

\begin_layout Standard
\begin_inset Formula $c{}_{jk}$
\end_inset

 - k-ty współczynnik wagowy mieszaniny dla stanu 
\begin_inset Formula $j$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula $b{}_{jk}$
\end_inset

 - k-te prawdopodobieńśtwo obserwacji dla stanu 
\begin_inset Formula $j$
\end_inset

.
\end_layout

\begin_layout Standard
Duża liczba parametrów w przypadku mieszanin o większej liczbie rozkładów
 wymusza użycie dużej ilości danych treningowych.
 Można jednak uprościć model redukując liczbę jego parametrów np.
 poprzez: 
\end_layout

\begin_layout Itemize
wiązanie parametrów, podczas którego stosuje się wspólną macierz kowariancji
 dla tych rozkładów, dla których wartości kowariancji są zbliżone,
\end_layout

\begin_layout Itemize
zastosowanie diagonalnej macierzy kowariancji, gdzie zakłada się, że elementy
 wektora cech są wzajemnie nieskorelowane, dlatego dopuszczalne jest zastosowani
e macierzy posiadającej elementy tylko na diagonali, powstają przez to błędy
 aproksymacji, które można minimalizować przez zastosowanie większej liczby
 rozkładów.
\end_layout

\begin_layout Standard
Prawdopodobieństwo 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $P(O,\, X|\text{Λ}{}_{m})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang polish
 (gdzie sekwencja wektorów 
\begin_inset Formula $X$
\end_inset

 oznacza sekwencję obserwacji 
\begin_inset Formula $o$
\end_inset

) wygenerowania przykładowej sekwencji wektorów obserwacji 
\begin_inset Formula $o_{1}$
\end_inset

,
\begin_inset Formula $o_{2}$
\end_inset

,
\begin_inset Formula $o_{4}$
\end_inset

,
\begin_inset Formula $o_{6}$
\end_inset

 nawiązując do modelu przedstawionego na rysunku 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys8"

\end_inset

 oblicza się następująco:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
P(O,\, X|\text{Λ}{}_{m})=a_{12}b_{2}(o_{1})a_{22}b_{2}(o_{2})a_{23}b_{3}(o_{4})a_{34}b_{4}(o_{6})a_{45}
\end{equation}

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "TM"

\end_inset


\end_layout

\begin_layout Standard
W praktyce jedynie sekwencja obserwacji 
\begin_inset Formula $O$
\end_inset

 jest znana, natomiast sekwencja stanów 
\begin_inset Formula $X$
\end_inset

 jest ukryta.
 Wymagane prawdopodobieństwo jest wyliczane przez sumę wszystkich możliwych
 sekwencji stanów 
\begin_inset Formula $X=x(1),\, x(2),\, x(3),\,...,\, x(T)$
\end_inset

 daną wzorem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(O|\text{Λ}{}_{m})=\sum_{X}a_{x(0)x(1)}\prod_{t=1}^{T}b_{x(t)}(o_{t})a_{x(t)x(t+1)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Jako alternatywę dla powyższego wzoru można rozważać w przybliżeniu, najbardziej
 prawdopodobną sekwencję stanów daną wzorem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(O|\text{Λ}{}_{m})=\underset{X}{max}\left\{ a_{x(0)x(1)}\prod_{t=1}^{T}b_{x(t)}(o_{t})a_{x(t)x(t+1)}\right\} 
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Gdzie:
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
\begin_inset Formula $x(0)$
\end_inset

 i 
\begin_inset Formula $x(T+1)$
\end_inset

 to stan pierwszy i ostatni modelu czyli stany nieemitujące.
 
\end_layout

\begin_layout Standard
Zakłada się, że parametry 
\begin_inset Formula $a{}_{ij}$
\end_inset

 oraz 
\begin_inset Formula $b_{j}(o_{t})$
\end_inset

 są znane dla każdego modelu.
 
\begin_inset Quotes pld
\end_inset

Tutaj właśnie leży elegancja i skuteczność metody HMM
\begin_inset Quotes prd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Htkb"

\end_inset


\end_layout

\begin_layout Section
Trenowanie 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

 
\backslash
subsection{Przebieg}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Schemat blokowy fazy trenowania modeli Markowa widoczny jest na rysunku
 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys9"

\end_inset

.
\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename hmm-trenowanie.png
	display false
	scale 90

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Trenowanie modeli Markowa 
\begin_inset CommandInset label
LatexCommand label
name "rys9"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "TM"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Gdzie:
\end_layout

\begin_layout Standard
\begin_inset Formula $\sum_{j}$
\end_inset

 - macierz kowariancji,
\end_layout

\begin_layout Standard
\begin_inset Formula $\mu{}_{j}$
\end_inset

 - wektor średni obserwacji,
\end_layout

\begin_layout Standard
\begin_inset Formula $A{}_{T}$
\end_inset

 - macierz przejść modelu.
\end_layout

\begin_layout Standard
Jednofonowe modele Markowa dla ciszy i krótkich pauz są przedstawione kolejno
 na rysunku 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys10"

\end_inset

 oraz 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys11"

\end_inset

.
\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename hmm-cisza.png
	display false

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Model HMM dla ciszy
\begin_inset CommandInset label
LatexCommand label
name "rys10"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
W modelu ciszy mamy dodatkowe przejście ze stanu 2 do stanu 4 oraz ze stanu
 4 do stanu 2.
\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename hmm-pauza.png
	display false

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Model HMM dla krótkiej pauzy
\begin_inset CommandInset label
LatexCommand label
name "rys11"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
W modelu krótkiej pauzy mamy dodatkowe przejście pomiędzy stanami 1 oraz
 3 czyli stanami nieemitującymi.
\end_layout

\begin_layout Standard
Stan 3 z modelu ciszy oraz stan 2 z modelu krótkiej pauzy są takie same.
 Model krótkiej pauzy tworzymy na podstawie modelu ciszy, usuwając stany
 2 oraz 4, powstaje wówczas model trzy-stanowy, gdzie poprzedni stan 3 staje
 się stanem 2 modelu.
\end_layout

\begin_layout Standard
W przypadku gdy najmniejszą niepodzielną jednostką fonetyczną systemu są
 fonemy trzeba rozpatrywać modele nie tylko dla jednofonów, lecz również
 dla trójfonów, czyli możliwych kombinacji fonemów w otoczeniu innych fonemów.
\end_layout

\begin_layout Standard
Zapis jednofonowy pokazany jest na rysunku 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys12"

\end_inset

.
\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename jednofony.png
	display false

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Zapis jednofonowy 
\begin_inset CommandInset label
LatexCommand label
name "rys12"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Natomiast zapis trójfonowy na rysunku 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys13"

\end_inset

.
\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename trojfony.png
	display false

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Zapis trójfonowy 
\begin_inset CommandInset label
LatexCommand label
name "rys13"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Znak 
\begin_inset Quotes pld
\end_inset

-
\begin_inset Quotes prd
\end_inset

 oznacza fonem poprzedzający, natomiast znak 
\begin_inset Quotes pld
\end_inset

+
\begin_inset Quotes prd
\end_inset

 fonem następujący.
\end_layout

\begin_layout Standard
Modele HMM są trenowane dla każdego słowa znajdującego się w słowniku systemu
 poprzez próbki dźwięku nagrane dla tego słowa.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

 
\backslash
subsection{Algorytm Bauma-Welcha}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Algorytm ten jest oparty na kryterium ML (ang.
 Maximum Likelihood) - maksymalizacji prawdopodobieństwa wygenerowania sekwencji
 obserwacji przez model HMM.
 Wykorzystywany jest w procesie trenowania HMM.
 Jest to procedura iteracyjna w wyniku której możemy otrzymać lepsze estymaty
 parametrów HMM.
 Schemat blokowy przedstawiony jest na rysunku 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys14"

\end_inset

.
\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename baum-welch.png
	display false

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Reestymacja Bauma-Welcha 
\begin_inset CommandInset label
LatexCommand label
name "rys14"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "TM"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Początkowe parametry HMM określane są na zasadzie zgadywania, dokładniejsze
 (w sensie największego pradopodobieństwa) parametry mogą być znalezione
 dopiero podczas reestymacji.
 Estymaty parametrów 
\begin_inset Formula $\mu{}_{j}$
\end_inset

 oraz 
\begin_inset Formula $\sum_{j}$
\end_inset

 wyznaczane są ze wzorów:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{\mu_{j}}=\frac{\sum_{t=1}^{T}L_{j}(t)o_{t}}{\sum_{t=1}^{T}L_{j}(t)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{\sum}_{j}=\frac{\sum_{t=1}^{T}L_{j}(t)(o_{t}-\mu_{j})'}{\sum_{t=1}^{T}L_{j}(t)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Gdzie: 
\end_layout

\begin_layout Standard
\begin_inset Formula $L_{j}(t)$
\end_inset

 - oznacza prawdopodobieństwo bycia w stanie 
\begin_inset Formula $j$
\end_inset

 w czasie 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Standard
Podobne, lecz trochę bardziej skomplikowane są wzory na estymaty prawdopobieństw
 przejść pomiędzy stanami, szczegóły znajdują się w rozdziale 8 pozycji
 
\begin_inset CommandInset citation
LatexCommand cite
key "Htkb"

\end_inset

.
\end_layout

\begin_layout Standard
Do obliczenia prawdopodobieństwa 
\begin_inset Formula $L_{j}(t)$
\end_inset

 wykorzystuje się algorytm 
\shape italic
Forward-Backward.
\end_layout

\begin_layout Standard
Prawdodobieństwo 
\shape italic
forward
\shape default
 dla modelu 
\emph on
M
\emph default
 zawierającemu 
\emph on
N
\emph default
 stanów jest zdefiniowane jako:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
\alpha_{j}(t)=P(o_{1},\,...,\, o_{t},\, x(t)=j\mid M)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Jest to połączone prawdopodobieństwo obserwacji pierwszego 
\begin_inset Formula $t$
\end_inset

 wektora cech i bycia w stanie 
\begin_inset Formula $j$
\end_inset

 w czasie 
\begin_inset Formula $t$
\end_inset

.
 Obliczone jest za pomocą rekursji danej wzorem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\alpha_{j}(t)=\left[\sum_{i=2}^{N-1}\alpha_{j}(t-1)a_{ij}\right]b_{j}(o_{t})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Ta rekursja polega na tym, że prawdopodobieństwo bycia w stanie 
\begin_inset Formula $j$
\end_inset

 w czasie 
\begin_inset Formula $t$
\end_inset

 oraz emitowania obserwacji można wywnioskować poprzez zsumowanie prawdopodobień
stw 
\shape italic
forward
\shape default
 dla wszystkich możliwych poprzedników stanów determinowanych przez prawdopodobi
eństwa przejść 
\begin_inset Formula $a_{ij}$
\end_inset

.
 Stany 1 oraz 
\emph on
N
\emph default
 są stanami nieemitującymi.
 Początkowe warunki powyższej rekursji są następujące:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
\alpha_{1}(1)=1
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
\alpha_{j}(1)=a_{1j}b_{j}(o_{1})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
dla 
\begin_inset Formula $1<j<N$
\end_inset

.
\end_layout

\begin_layout Standard
Zatem finalne waruki:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\alpha_{N}(T)=\sum_{i=2}^{N-1}\alpha_{i}(T)a_{iN}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Trzeba zauważyć, że z definicji 
\begin_inset Formula $\alpha_{j}(t)$
\end_inset

,
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
P(O\mid M)=\alpha_{N}(T)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Stąd obliczenie prawdopodobieństwa 
\shape italic
forward
\shape default
 również daje prawdopodobieństwo całkowite 
\begin_inset Formula $P(O\mid M)$
\end_inset

.
\end_layout

\begin_layout Standard
Z kolei prawdopodobieństwo 
\shape italic
backward 
\shape default
jest zdefiniowane jako:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
\beta_{j}(t)=P(o_{t+1},\,...,\, o_{T},\, x(t)=j\mid M)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Jak w przypadku prawdopodobieństwa 
\shape italic
forward, 
\shape default
prawdopodobieństwo 
\shape italic
backward 
\shape default
również liczone jest za pomocą rekursji:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\beta_{j}(t)=\sum_{j=2}^{N-1}a_{1j}b_{j}(o_{t+1})\beta_{j}(t+1)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
z warunkami początkowymi:
\end_layout

\begin_layout Standard
\align center

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
\begin_inset Formula 
\begin{equation}
\beta_{j}(T)=a_{iN}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
dla 
\begin_inset Formula $1<i<N$
\end_inset

 i finalne warunki:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
\beta_{1}(1)=\sum_{j=2}^{N-1}a_{1j}b_{j}(o_{1})\beta_{j}(1)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Trzeba zauważyć, że w powyższych definicjach prawdopodobieństwo 
\shape italic
forward
\shape default
 jest prawdopodobieństwem połączonym podczas, gdy prawdopodobieństwo 
\shape italic
backward
\shape default
 jest prawdopodobieństwem warunkowym.
 
\end_layout

\begin_layout Standard
Prawdopodobieństwo przebywania w danych stanie jest wyznaczane przez iloczyn
 dwóch prawdopodobieństw zgodnie ze wzorem:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
\alpha_{j}(t)\beta_{j}(t)=P(O,x(t)=j\mid M)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Stąd:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
L_{j}(t)=P(x(t)=j\mid O,M)=\frac{P(O,x(t)=j\mid M)}{P(O|M)}=\frac{1}{P}\alpha_{j}(t)\beta_{j}(t)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Gdzie 
\begin_inset Formula $P=P(O|M)$
\end_inset

.
\end_layout

\begin_layout Standard
Operacja odcinania polega na zakończeniu sumowania prawdopodobieństw w algorytmi
e 
\shape italic
Forward-Backward,
\emph on
 gdy mamy doczynienia z bardzo dużą bazą treningową
\emph default
.

\shape default
 Nie wpływa ona na skuteczność rozpoznawania, lecz zmniejsza ilość obliczeń
 a co za tym idzie, złożoność obliczeniową algorytmu.
\end_layout

\begin_layout Standard
Zakłada się, że parametry dla HMM są reestymowane dla pojedyńczej sekwencji
 obserwacji, co odpowiada pojedyńczej próbce mowy nagranej do wytrenowania
 modelu.
 Do uzyskania dobrych estymat parametrów potrzebne jest wiele próbek tego
 samego słowa.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Htkb"

\end_inset


\end_layout

\begin_layout Standard
Podsumowując, problem estymacji parametrów polega na doborze jak największych
 prawdopodobieństw przejść pomiędzy stanami oraz prawdopodobieństw wystąpienia
 obserwacji.
 Najpierw ustalamy początkowe przybliżone wartości tych parametrów a następnie
 przebiega reestymacja parametrów, czyli próba znalezienia ich dokładniejszych
 wartości.
 
\begin_inset CommandInset citation
LatexCommand cite
key "RmHMM"

\end_inset


\end_layout

\begin_layout Section
Rozpoznawanie 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

 
\backslash
subsection{Przebieg}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Fazę rozpoznawania przedstawia schemat blokowy widoczny na rysunku 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys15"

\end_inset

.
\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename rozpoznawanie-hmm.png
	display false
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Schemat blokowy rozpoznawania 
\begin_inset CommandInset label
LatexCommand label
name "rys15"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "TM"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Najważniejszym etapem tej fazy jest wyznaczenie sekwencji najbardziej prawdopodo
bnych stanów a więc optymalnej ścieżki w modelu.
 Do rozwiązania tego problemu stosowany jest zazwyczaj algorytm Viterbiego.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

 
\backslash
subsection{Algorytm Viterbiego}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Na rysunku 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys17"

\end_inset

 przedstawiony jest przykład użycia algorytmu Viterbiego dla modelu z rysunku
 
\begin_inset CommandInset ref
LatexCommand ref
reference "rys16"

\end_inset

.
\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename hmm-viterbi.png
	display false

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Przykładowy model HMM
\begin_inset CommandInset label
LatexCommand label
name "rys16"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename viterbi.png
	display false

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Algorytm Viterbiego 
\begin_inset CommandInset label
LatexCommand label
name "rys17"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "TM"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
W każdym kolejnym kroku algorytmu zapamiętywany jest argument maksymalny,
 wynikiem działania algorytmu jest ścieżka dająca największe prawdopodobieństwo,
 czyli najbardziej prawdopodobna sekwencja jednostek fonetycznych które
 zostały przyjęte.
 
\begin_inset CommandInset citation
LatexCommand cite
key "RmHMM"

\end_inset


\end_layout

\begin_layout Standard
Od strony matematycznej prawdopodobieństwo to, jest wyliczane podobnie jak
 prawdopodobieństwo 
\shape italic
forward
\shape default
 za pomocą rekursji:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\phi_{j}(t)=\underset{t}{max\{\phi_{i}(t-1)a_{ij}\}b_{j}(o_{t})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\phi_{1}(1)=1
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\phi_{j}(1)=a_{1j}b_{j}(o_{1})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
dla 
\begin_inset Formula $1<j<N$
\end_inset

.
\end_layout

\begin_layout Standard
Największe prawdopodobieństwo 
\begin_inset Formula $\hat{P}=(O|M)$
\end_inset

 dane jest wzorem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\phi_{N}(T)=\underset{i}{max}\{\phi_{i}(T)a_{iN}\}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Jak w przypadku reestymacji tutaj też jest stosowana skala logarytmiczna,
 stąd równanie ma postać:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\psi_{j}(t)=\underset{i}{max}\{\psi_{i}(t-1)+log(a_{ij})\}+log(b_{j}(o_{t}))\}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset CommandInset citation
LatexCommand cite
key "Htkb"

\end_inset


\end_layout

\end_body
\end_document
