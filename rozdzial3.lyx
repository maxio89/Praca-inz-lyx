#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass pwszdpl
\options pdflatex
\use_default_options false
\maintain_unincluded_children false
\language polish
\language_package default
\inputencoding latin2
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 0
\use_esint 0
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Indeks
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language polish
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Ukryte Modele Markowa jako jedna z metod klasyfikacji
\end_layout

\begin_layout Standard
Współczesne systemy rozpoznawania mowy zakadają, że sygnał mowy jest sekwencją
 pewnych elementarnych jednostek fonetycznych (np.
 głosek, fonemów, słów).
 Charakteruzyje się on również pewna przypadkowością.
 Wypowiedź tego samego mówcy za każdym razem posiada niepowtarzalny przebieg.
 A coza tym idzie nie możemy przyporządkować jej jednoznacznej sekwencji
 jednostek mowy.
 Wiąże się to z tym, że nagrany sygnał mowy często bywa zaszumiony i zniekształc
ony.
\end_layout

\begin_layout Standard
Metody klasyfikacji wykorzystywane w systemach rozpoznawania mowy możemy
 podzielić na dwie kategorie:
\end_layout

\begin_layout Itemize
metody deterministyczne, gdzie obliczane są błedy porównując dźwięk ze wzorcem,
\end_layout

\begin_layout Itemize
metody niederministyczne, gdzie obliczamy wartości prawdopodobieństw, które
 reprezentują dopasowanie dźwięku do stosowanych modeli probalistycznych.
 
\begin_inset CommandInset citation
LatexCommand cite
key "RmHMM"

\end_inset


\end_layout

\begin_layout Standard
Do metod deterministycznych należy m.in.
 nieliniowa transformata czasowa w skrócie DTW (ang.
 dynamic time wrapping), metoda skuteczna dla izolowanych słów.
 
\end_layout

\begin_layout Standard
Inne ograniczenia metod deterministycznych:
\end_layout

\begin_layout Itemize
duża zajętość pamięci potrzebnej na przechowywanie wzorców (dla dużych słowników
),
\end_layout

\begin_layout Itemize
czas rozpoznawania proporcjonalny do rozmiaru słownika.
 
\begin_inset CommandInset citation
LatexCommand cite
key "TM"

\end_inset


\end_layout

\begin_layout Standard
Biorąc pod uwagę to, że bardziej naturalnym dla człowieka jest wypowiadanie
 słów ciągiem (bez znaczących przerw między nimi) oraz, że przy analizie
 sygnału mowy warto uwzględnić jego przypadkowość, metody niederministyczne
 osiągają lepszą skuteczność rozpoznawania.
 Do takich właśnie metod należą Ukryte Modele Markowa, w skrócie HMM (ang.
 hidden markov models).
 
\end_layout

\begin_layout Section
Wprowadzenie teoretyczne
\end_layout

\begin_layout Standard
\begin_inset Quotes pld
\end_inset

Ukryte Modele Markowa stanowią serce większości współczesnych systemów rozpoznaw
ania mowy.
\begin_inset Quotes prd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Ops"

\end_inset

 Sprawdzają się również w wielu innych zastosowaniach, tam gdzie mamy doczynieni
a z sygnałem niederministycznym, np.:
\end_layout

\begin_layout Itemize
rozpoznawanie obrazów,
\end_layout

\begin_layout Itemize
modelowaniu DNA,
\end_layout

\begin_layout Itemize
oraz modelowaniu danych ekonomicznych.
\end_layout

\begin_layout Standard
Pierwsze prace na temat Ukrytych (niejawnych) Modeli Markowa prowadził Baum
 wraz ze współpracownikami w latach 60-tych oraz 70-tych.
 Dotyczyły one metody estymacji parametrów modeli HMM nazwanej algorytmem
 Bauma-Welcha.
 Algorytm ten jest oparty na kryterium (ML) (Maximum Likelihood) maksymalizacji
 prawdopodobieństwa wygenerowania sekwencji obserwacji przez model HMM.
 
\begin_inset CommandInset citation
LatexCommand cite
key "RmHMM"

\end_inset


\end_layout

\begin_layout Standard
W bloku klasyfikacji nastepuje porównanie nadchodzacych ciagów obrazów wypowiedz
i ze znajdujacymi sie w pamieci wzorcami, które stanowia uogólniony (usredniony)
 opis klas dzwieków.
 Klasa moga byc fonemy, wyrazy lub nawet całe zdania.
 Obrazy wzorcowe sa tworzone w procesie uczenia.
\end_layout

\begin_layout Standard
W przypadku rozpoznawania mowy rozważa się jednak nieco odmienną sytuację,
 gdy łańcuch q uznawany jest za niejawny (ukryty).
 Znana jest natomiast sekwencja obserwacji O.
 W przypadku mowy, obserwacja jest to wektor cech wyekstrahowanych z pojedynczej
 ramki nagrania.
\end_layout

\begin_layout Section
Algorytm Bauma-Welcha
\end_layout

\begin_layout Section
Algorytm Viterbiego
\end_layout

\end_body
\end_document
